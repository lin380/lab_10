---
title: "Lab 10"
author: "<Your Name Here>"
date: "11/15/2021"
output: 
  html_document: 
    toc: yes
    number_sections: yes
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
library(tidyverse)           # data manipulation
library(quanteda)            # tokenization and document-frequency matrices
library(quanteda.textstats)  # descriptive text statistics
library(quanteda.textmodels) # Naive Bayes classifier

source("functions/functions.R") # plot_indicative_features(), evaluate_training_model()
knitr::opts_chunk$set(echo = FALSE) # do not show code by default
```

# Overview

The aim of this script will be creating a predictive model for author detection. Specifically we will try to correctly predict the author of the once [disputed Federalist papers](https://en.wikipedia.org/wiki/The_Federalist_Papers). The disputed papers involved the debate whether "Alexander Hamilton" or "James Madison" was the author of some or all of the papers. Modern opinion is that James Madison is the author of the disputed papers [@Mosteller1963]. We will use the same data available to earlier scholars to build a Naive Bayes Text Classifier aimed a predicting the author(s) of the disputed papers. 

# Tasks

## Orientation

```{r fed-df-read-dataset, message=FALSE}
fed_df <- 
  read_csv(file = "data/derived/federalist_papers_curated.csv") # read curated dataset

glimpse(fed_df) # preview dataset
```

```{r fed-df-read-data-dictionary, message=FALSE}
fed_data_dictionary <- read_csv(file = "data/derived/federalist_papers_curated_data_dictionary.csv") # read data dictionary

fed_data_dictionary %>% 
  print_pretty_table(caption = "Federalist papers data dictionary.")
```

```{r fed-df-description}
fed_df %>% 
  janitor::tabyl(author, disputed)
```

## Preparation

```{r fed-corpus-create}
# Create corpus object
fed_corpus <- 
  fed_df %>% # data frame
  select(-title) %>% # remove the title column
  corpus() # create the corpus object

fed_corpus %>% 
  summary(n = 10)
```

```{r fed-corpus-subset}
fed_corpus <- 
  fed_corpus %>% # corpus objuect
  corpus_subset(author != "John Jay") # remove John Jay authored papers

fed_corpus %>% 
  summary(n = 10)
```

## Feature engineering

```{r fed-tokens-create}
fed_tokens <- 
  tokens(fed_corpus, # corpus object
         what = "word", # tokenize by word
         remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE) %>% # remove numbers
  tokens_tolower() # lowercase the tokens

fed_tokens %>% # tokens object
  head(n = 5) # view the first observations
```

```{r fed-dfm-create}
fed_dfm <- 
  dfm(fed_tokens) # create document-frequency matrix

fed_dfm %>% # dfm object
  head(n = 5) # preview
```

```{r fed-dfm-topfeatures}
fed_dfm %>% # dfm object
  topfeatures(n = 20) # view most frequent features
```

```{r fed-dfm-topfeatures-author}
fed_dfm %>% # dfm object
  textstat_frequency(n = 10, groups = author) # get top frequency grouped by author
```

```{r fed-dfm-topfeatures-author-view}
fed_dfm %>% # dfm
  textstat_frequency(n = 25, groups = author) %>% # get top frequency grouped by author
  ggplot(aes(x = reorder(feature, frequency), 
             y = frequency, 
             fill = group)) + # mappings
  geom_col(show.legend = FALSE) + # bar plot (with no legend)
  coord_flip() + # flip x/y coordinates
  facet_wrap(~group, scales = "free") + # create separate plots for each author
  labs(x = "Words", y = "Raw frequency") # labels
```

```{r fed-dfm-weighted-topfeatures-author-view}
fed_dfm %>% # dfm
  dfm_tfidf() %>% # weigh frequency by tf-idf
  textstat_frequency(n = 25, groups = author, force = TRUE) %>% # get top frequency grouped by author
  ggplot(aes(x = reorder(feature, frequency), 
             y = frequency, 
             fill = group)) + # mappings
  geom_col(show.legend = FALSE) + # bar plot (with no legend)
  coord_flip() + # flip x/y coordinates
  facet_wrap(~group, scales = "free") + # create separate plots for each author
  labs(x = "Words", y = "TF-IDF") # labels
```

```{r fed-dfm-train-test}
# Create training and testing dfms
fed_dfm_train <- 
  fed_dfm %>% 
  dfm_subset(disputed == FALSE)

fed_dfm_train %>% 
  docvars() %>% 
  janitor::tabyl(author)

fed_dfm_test <- 
  fed_dfm %>% 
  dfm_subset(disputed == TRUE)

fed_dfm_test %>% 
  docvars() %>% 
  janitor::tabyl(author)
```

## Model training

```{r fed-fit-model}
# Train model
nb1 <- 
  textmodel_nb(x = fed_dfm_train, # document-feature matrix
               y = fed_dfm_train$author) # class labels

summary(nb1) # model summary
```

```{r fed-fit-explore}
plot_indicative_features(nb_model = nb1, top_n = 25)
```

```{r nb1-evaluate}
evaluate_training_model(nb1, classes = c("Alexander Hamilton", "James Madison"))
```


## Model testing

```{r fed-test-model-predictions}
# Test model predictions
dfm_matched <- 
  dfm_match(fed_dfm_test, # test dfm
            features = featnames(nb1$x)) # (left) join with trained model features

predicted_class <- predict(nb1, newdata = dfm_matched) # apply model to test dataset

predicted_class %>% 
  as_tibble(rownames = "names") %>% # convert to tibble with rownames as a column
  select(doc_id = names, prediction = value) %>% # rename columns
  arrange(doc_id) # sort by doc_id
```


## Evaluation

```{r fed-evaluate-predictions}
# Evaluate
actual_class <- dfm_matched$author # get actual class labels

tab_class <- table(actual_class, predicted_class) # cross-tabulate actual and predicted class labels

tab_class
```


## Model improvement

```{r fed-dfm-weighted-tfidf}
fed_dfm <- 
  fed_dfm %>% 
  dfm_tfidf()  # weight by term-frequency inverse-document frequency

fed_dfm_train <- 
  fed_dfm %>% 
  dfm_subset(disputed == FALSE)

fed_dfm_test <- 
  fed_dfm %>% 
  dfm_subset(disputed == TRUE)
```


```{r fed-weighted-fit-model}
nb2 <- 
  textmodel_nb(x = fed_dfm_train, # document-feature matrix
               y = fed_dfm_train$author) # class labels
```

```{r nb2-evaluate}
evaluate_training_model(nb2, classes = c("Alexander Hamilton", "James Madison"))
```

```{r fed-weighted-fit-explore}
plot_indicative_features(nb_model = nb2, top_n = 25)
```

```{r fed-test-model-weighted-predictions}
# Test model predictions
dfm_matched <- 
  dfm_match(fed_dfm_test, # test dfm
            features = featnames(nb2$x)) # (left) join with trained model features

predicted_class <- predict(nb2, newdata = dfm_matched) 

predicted_class %>% 
  as_tibble(rownames = "names") %>% # convert to tibble with rownames as a column
  select(doc_id = names, prediction = value) %>% # rename columns
  arrange(doc_id) # sort by doc_id
```

```{r fed-evaluate-weighted-predictions}
# Evaluate
actual_class <- dfm_matched$author # get actual class labels

tab_class <- table(actual_class, predicted_class) # cross-tabulate actual and predicted class labels

tab_class
```

# Assessment

# References


